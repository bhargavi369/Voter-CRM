{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "03xn3DMBV6Lf",
        "HttSm0mlRcSn"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1FdFYCTlDRAHCtRObKX0J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/resh1998/VoterCRM_Backend/blob/main/BackEnd/Data_Collection/Main_Code_PDF_to_Excel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mounting Drive"
      ],
      "metadata": {
        "id": "hBDEMtsdzquw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfG8-zE9zerv",
        "outputId": "1678ddcd-720d-4692-ea65-7ae7b4b69463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/Images\n",
        "!mkdir /content/drive/MyDrive/PDF_files\n",
        "!mkdir /content/drive/MyDrive/Raw_CSV_files\n",
        "!mkdir /content/drive/MyDrive/PDF_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khwg1UL-qaeK",
        "outputId": "71cfe95b-ebd4-4cd4-dcf6-9e07254e9d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Images’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/PDF_files’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Raw_CSV_files’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/PDF_files’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installing and Importing Packages"
      ],
      "metadata": {
        "id": "WU4g-0xA4mta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb594ed-1dc4-42b3-9dc7-bed4ca6cca5a",
        "id": "aWJdk5NJ4mtb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 1s (3,512 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 3,343 kB of archives.\n",
            "After this operation, 15.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libarchive-dev amd64 3.4.0-2ubuntu1.2 [491 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libleptonica-dev amd64 1.79.0-1 [1,389 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libtesseract-dev amd64 4.1.1-2build2 [1,463 kB]\n",
            "Fetched 3,343 kB in 1s (2,596 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 122578 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.4.0-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Selecting previously unselected package libleptonica-dev:amd64.\n",
            "Preparing to unpack .../libleptonica-dev_1.79.0-1_amd64.deb ...\n",
            "Unpacking libleptonica-dev:amd64 (1.79.0-1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2build2) ...\n",
            "Setting up libleptonica-dev:amd64 (1.79.0-1) ...\n",
            "Setting up libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!apt install tesseract-ocr\n",
        "!apt install libtesseract-dev\n",
        "!pip install Pillow\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97kZW0xC5QK1",
        "outputId": "d1773b66-f098-4990-daad-10606bac7e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (8.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 174 kB of archives.\n",
            "After this operation, 754 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.1 [174 kB]\n",
            "Fetched 174 kB in 1s (243 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 122709 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.86.1-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Setting up poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pytesseract import image_to_string\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xCS1QVpM4mtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing Dataframe"
      ],
      "metadata": {
        "id": "b2z0AONx_shk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.DataFrame(columns = ['voter_id', 'name', 'relation_name', 'relation_type', 'house_number', 'age', 'gender'])\n",
        "\n"
      ],
      "metadata": {
        "id": "T9V7SFvY_rGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Funtion to input text in Excel(DONT RUN)"
      ],
      "metadata": {
        "id": "03xn3DMBV6Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def write_to_dataframe(voter_id, name, relation_name, relation_type, house_number, age, gender):\n",
        "  \n",
        "#   global df\n",
        "\n",
        "#   new_row = {'voter_id': voter_id, 'name': name, 'relation_name': relation_name, \n",
        "#              'relation_type': relation_type, 'house_number': house_number, \n",
        "#              'age': age, 'gender': gender}\n",
        "\n",
        "#   df = df.append(new_row, ignore_index = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "cb6acGGcWIih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to get data from string (DONT RUN)"
      ],
      "metadata": {
        "id": "HttSm0mlRcSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "\n",
        "# def get_data_from_string(text):\n",
        "#   text = text.replace(\"\\n\", \" \")\n",
        "#   print(text)\n",
        "#   voter_id =  ''\n",
        "#   name = ''\n",
        "#   relation_name = ''\n",
        "#   relation_type = ''\n",
        "#   house_number = ''\n",
        "#   age = ''\n",
        "#   gender = ''\n",
        "\n",
        "#   if 'Husband' in text:\n",
        "\n",
        "#     name = re.search(r'(?<=Name:).*(?=Husband\\'s Name:)', text)\n",
        "\n",
        "#     relation_name = re.search(r'(?<=Husband\\'s Name:).*(?=House Number:)', text)\n",
        "#     relation_type = 'H'\n",
        "  \n",
        "#   elif 'Wife' in text:\n",
        "    \n",
        "#     name = re.search(r'(?<=Name:).*(?=Wife\\'s Name:)', text)\n",
        "\n",
        "#     relation_name = re.search(r'(?<=Wife\\'s Name:).*(?=House Number:)', text)\n",
        "    \n",
        "#     relation_type = 'W'\n",
        "  \n",
        "#   elif 'Father' in text:\n",
        "    \n",
        "#     name = re.search(r'(?<=Name:).*(?=Father\\'s Name:)', text)\n",
        "    \n",
        "#     relation_name = re.search(r'(?<=Father\\'s Name:).*(?=House Number:)', text)\n",
        "    \n",
        "#     relation_type = 'F'\n",
        "  \n",
        "#   house_number = re.search(r'(?<=House Number:).*(?=Age:)', text)\n",
        "\n",
        "#   age = re.search(r'(?<=Age:).*(?=Gender:)', text)\n",
        "\n",
        "#   gender = re.search(r'(?<=Gender:).*(?=)', text)\n",
        "\n",
        "#   print(name, '\\n', relation_name, '\\n', house_number, '\\n', age, '\\n', gender, '\\n')\n",
        "\n",
        "#   write_to_dataframe(voter_id, name, relation_name, relation_type, house_number, age, gender)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "etvHcFVERbVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to Get Single Voter"
      ],
      "metadata": {
        "id": "9Lp8kJU_-pgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def crop_page(contours, y_min, page_no):\n",
        "\n",
        "  # read image from folder\n",
        "  page_name = \"/content/drive/MyDrive/Images/Page_\" + str(page_no) + \".jpg\"\n",
        "  im = cv2.imread(page_name)\n",
        "\n",
        "  # getting width of the image\n",
        "  (h, w, s) = im.shape\n",
        "\n",
        "  # converting the image to grayscale and binarizing it\n",
        "  im = cv2.bilateralFilter(im,9,75,75)\n",
        "  im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "  im = cv2.adaptiveThreshold(im, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 15)\n",
        "\n",
        "  im = Image.fromarray(im)\n",
        "\n",
        "  # getting the header of the page\n",
        "  header_crop = (0, 0, w, y_min - 2)\n",
        "  header_crop_im = im.crop(header_crop)\n",
        "\n",
        "  text_header = image_to_string(header_crop_im, config = '--psm 6')\n",
        "\n",
        "  # looping through each voter\n",
        "  voter_shift = (-5, -52, 228, 5)\n",
        "  voter_id_shift = (-600, 0, 0, 265)\n",
        "  voter_no_shift = (-20, -3, 686, 294)\n",
        "\n",
        "  for contour in contours:\n",
        "    (x, y, w, h) = cv2.boundingRect(contour)\n",
        "    voter_crop = tuple(np.subtract((x, y, x+w, y+h), voter_shift))\n",
        "    voter_crop_im = im.crop(voter_crop)\n",
        "\n",
        "    voter_id_crop = tuple(np.subtract((x, y, x+w, y+h), voter_id_shift))\n",
        "    voter_id_crop_im = im.crop(voter_id_crop)\n",
        "\n",
        "    voter_no_crop = tuple(np.subtract((x, y, x+w, y+h), voter_no_shift))\n",
        "    voter_no_crop_im = im.crop(voter_no_crop)\n",
        "    \n",
        "    text_voter =  image_to_string(voter_crop_im, config = '--psm 6')\n",
        "    text_voter_id =  image_to_string(voter_id_crop_im, config = '--psm 6')\n",
        "    text_voter_no =  image_to_string(voter_no_crop_im, config = '--psm 6')\n",
        "\n",
        "    # get_data_from_string(text_voter)\n",
        "\n",
        "    # appending to dataframe\n",
        "    new_row = {'voter_no': text_voter_no, 'voter_id': text_voter_id,'text': text_voter, 'header_section': text_header}\n",
        "\n",
        "    global df\n",
        "    df = df.append(new_row, ignore_index = True)\n"
      ],
      "metadata": {
        "id": "4sdEcYx--oJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contouring the Image"
      ],
      "metadata": {
        "id": "yj7aDtS9-_gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def contour_page(im):\n",
        "\n",
        "  gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "  gray = cv2.medianBlur(gray, 5)\n",
        "  gray = cv2.GaussianBlur(gray, (21, 21), 1)\n",
        "\n",
        "  gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
        "  dilated = cv2.dilate(gray, kernel, iterations=1)\n",
        "\n",
        "  eroded = cv2.erode(dilated, kernel, iterations=1)\n",
        "\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "  morph = cv2.morphologyEx(eroded, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
        "\n",
        "  contours, hierarchy = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours = [c for c in contours if cv2.contourArea(c) > 100000 and cv2.contourArea(c) < 600000]\n",
        "  \n",
        "  y_min = math.inf\n",
        "\n",
        "  for contour in contours:\n",
        "      (x, y, w, h) = cv2.boundingRect(contour)  \n",
        "      if y < y_min:\n",
        "        y_min = y\n",
        "      # cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "  \n",
        "  #im = cv2.bilateralFilter(im,9,75,75)\n",
        "  #im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "  #im = cv2.adaptiveThreshold(im, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 15)\n",
        "\n",
        "  return contours, y_min"
      ],
      "metadata": {
        "id": "0wu6YHzw-9ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Converting PDF pages to single Image Page"
      ],
      "metadata": {
        "id": "zhtzrcYK453F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "def convert_pdf_to_images(filename):\n",
        "  pdfs = \"/content/drive/MyDrive/PDF_files/\" + filename + \".pdf\"\n",
        "  pages = convert_from_path(pdfs, 350)\n",
        "  pdf_len = len(pages)\n",
        "\n",
        "  for i in range(2, pdf_len-1):\n",
        "    image_name = \"/content/drive/MyDrive/Images/Page_\" + str(i+1) + \".jpg\"\n",
        "    pages[i].save(image_name, \"JPEG\")\n",
        "  \n",
        "  return pdf_len\n"
      ],
      "metadata": {
        "id": "XPEDvHVy5CM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read and convert each image"
      ],
      "metadata": {
        "id": "anO45LN--4sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## page_count = len(pages)\n",
        "\n",
        "def read_and_convert_image(pdf_len):\n",
        "# read image from directory\n",
        "  for i in range(3, pdf_len):\n",
        "    image_name = \"/content/drive/MyDrive/Images/Page_\" + str(i) + \".jpg\"\n",
        "    im = cv2.imread(image_name)\n",
        "\n",
        "    contours, y_min = contour_page(im)\n",
        "\n",
        "    crop_page(contours, y_min, i)\n",
        "    "
      ],
      "metadata": {
        "id": "N2efPPem7DTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main function and Reading PDF files"
      ],
      "metadata": {
        "id": "0LmJ-GNSDRHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns = ['voter_no', 'voter_id','text', 'header_section'])"
      ],
      "metadata": {
        "id": "X367MtqkIaNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "pdf_files = Path(\"/content/drive/MyDrive/PDF_files\").glob(\"*.pdf\")\n",
        "\n",
        "for pdf in pdf_files:\n",
        "\n",
        "  filename = pdf.stem\n",
        "  pdf_len = convert_pdf_to_images(filename)\n",
        "  read_and_convert_image(pdf_len)\n",
        "  \n",
        "  csv_path = '/content/drive/MyDrive/Raw_CSV_files/' + filename + '.csv'\n",
        "  df.to_csv(csv_path)\n",
        "  \n",
        "  !rm -rf /content/drive/MyDrive/Images\n",
        "  \n",
        "  !mkdir /content/drive/MyDrive/Images\n",
        "\n",
        "  \n",
        "  df = df[0:0]\n",
        "\n"
      ],
      "metadata": {
        "id": "6uf1FZVw0F46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}