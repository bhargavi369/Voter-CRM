{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l8knu3GI6mQa",
        "dCytpE9xwfng",
        "P7r2GaJJVieh",
        "07YvJdz0C3j2",
        "YoB_zqs9a2hI"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/resh1998/VoterCRM_Backend/blob/main/BackEnd/Data_Collection/Copy_of_Clean_csv_data_Updated_Kurnool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Steps to Run the File"
      ],
      "metadata": {
        "id": "pfszzxsNrQYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Make sure all the files converted from PDF to CSV are in Raw_CSV_files\n",
        "2. Mount the drive (commented as Step 2)\n",
        "3. Create CSV_files folder. If the folder already exists then output message would be \"Cannot create directory\" (commented as Step 3)\n",
        "4. Run the remaining cells one after the other"
      ],
      "metadata": {
        "id": "VJHcj4EurVJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Mounting Drive"
      ],
      "metadata": {
        "id": "l8knu3GI6mQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXsSKRjV6TyI",
        "outputId": "52635783-5dc5-4202-8a59-e9a0687b45c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3\n",
        "!mkdir /content/drive/MyDrive/CSV_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hMcUlrQ6Ygm",
        "outputId": "ad0785cf-0521-4127-dc77-f962cb6534de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/CSV_files’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text column Split into diff columns"
      ],
      "metadata": {
        "id": "dCytpE9xwfng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Age'] = df['text'].str.extract(r'((?<=Age)(.|\\s)*(?=Gender))')"
      ],
      "metadata": {
        "id": "zarDL8LZXIoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_col(df):\n",
        "\n",
        "  df['text'] = df.text.str.replace('\\n', ' ')\n",
        "\n",
        "  df['text'] = df.text.str.replace('Name ', 'Name')\n",
        "  df['text'] = df.text.str.replace('Gender ', 'Gender')\n",
        "  df['text'] = df.text.str.replace('Age ', 'Age')\n",
        "  df['text'] = df.text.str.replace('House Number ', 'House Number')\n",
        "\n",
        "  df['Age'] = df['text'].str.extract(r'((?<=Age).*(?=Gender))')\n",
        "  df['Gender'] = df['text'].str.extract(r'((?<=Gender).*(?=))')\n",
        "\n",
        "  def condition(x):\n",
        "    if 'Husband' in x:\n",
        "      return '2'\n",
        "    elif 'Wife' in x:\n",
        "      return '4'\n",
        "    elif 'Father' in x:\n",
        "      return '1'\n",
        "    elif 'Mother' in x:\n",
        "      return '3'\n",
        "    elif 'Guru' in x:\n",
        "      return '6'\n",
        "    else:\n",
        "      return '5'\n",
        "\n",
        "  df['Relation_type'] = df['text'].apply(condition)\n",
        "\n",
        "  df['House_Number'] = df['text'].str.extract(r'((?<=Number).*(?=Age))')\n",
        "\n",
        "  df['text'] = df.text.str.replace('Husband', 'Relation')\n",
        "  df['text'] = df.text.str.replace('Wife', 'Relation')\n",
        "  df['text'] = df.text.str.replace('Father', 'Relation')\n",
        "  df['text'] = df.text.str.replace('Mother', 'Relation')\n",
        "  df['text'] = df.text.str.replace('Other', 'Relation')\n",
        "  df['text'] = df.text.str.replace('Guru', 'Relation')\n",
        "  df['text'] = df.text.str.replace('Legal Guardian', 'Relation')\n",
        "  df['text'] = df.text.str.replace('\\'s', '')\n",
        "\n",
        "  df['Name'] = df['text'].str.extract(r'((?<=Name).*(?=House))')\n",
        "  df['Name'] = df['Name'].str.split('Relation').str[0]\n",
        "\n",
        "  df['text'] = df['text'].str.split('House').str[0]\n",
        "  df['text'] = df['text'].str.split('Relation').str[1]\n",
        "\n",
        "  df['text'] = df.text.str.replace('Name', '')\n",
        "\n",
        "  df.rename(columns= {'text': 'Relation_Name'}, inplace = True)\n",
        "\n",
        "  df['Name'] = df['Name'].str.replace('!', 'I')\n",
        "  df['Name'] = df['Name'].str.replace('\\W', ' ', regex = True)\n",
        "  df['Name'] = df.Name.str.strip()\n",
        "\n",
        "  df['Relation_Name'] = df['Relation_Name'].str.replace('!', 'I')\n",
        "  df['Relation_Name'] = df['Relation_Name'].str.replace('\\W', ' ', regex = True)\n",
        "  df['Relation_Name'] = df.Relation_Name.str.strip()\n",
        "\n",
        "  df['House_Number'] = df.House_Number.str.strip()\n",
        "  df['House_Number'] = df.House_Number.str.replace(r'^\\W*', ' ', regex = True)\n",
        "\n",
        "  df['Age'] = df.Age.str.replace('\\W', '', regex = True)\n",
        "  df['Gender'] = df.Gender.str.replace('\\W', '', regex = True)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "FG_1l0LP-udP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Voter columns Preprocessing"
      ],
      "metadata": {
        "id": "P7r2GaJJVieh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def process_voter_id_col(df):\n",
        "\n",
        "  df['voter_id'] = df.voter_id.str.replace(r'((\\n).*)', ' ', regex = True)\n",
        "  df['voter_id'] = df.voter_id.str.replace('\\n', '', regex = True)\n",
        "  df['voter_id'] = df.voter_id.str.replace('\\W', '', regex = True)\n",
        "\n",
        "  df['voter_id_str_part'] = df.voter_id.str.findall(r'([a-zA-Z]+)')\n",
        "  df['voter_id_str_part'] = df.voter_id_str_part.str.join(',').astype(str)\n",
        "\n",
        "  df['voter_id_str_part_get_unique'] = df.voter_id.str.findall(r'([a-zA-Z]+)').str[0]\n",
        "  list_str = list(df['voter_id_str_part_get_unique'].unique())\n",
        "\n",
        "  list_str_n = list()\n",
        "\n",
        "  for i in list_str:\n",
        "    if i is not None and len(str(i)) >= 3 and str(i) != 'nan':\n",
        "      i = str(i)[:3]\n",
        "      list_str_n.append(str(i))\n",
        "\n",
        "  list_str_n = list(np.unique(np.array(list_str_n)))\n",
        "\n",
        "  df['voter_id_no_part'] = df.voter_id.str.findall(r'(\\d+)')\n",
        "  df['voter_id_no_part'] = df.voter_id_no_part.str.join(',').astype(str)\n",
        "  df['voter_id_no_part'] = df['voter_id_no_part'].str.replace(',', '')\n",
        "\n",
        "  def add_zeros(x):\n",
        "    if x is not None and len(x) < 7:\n",
        "      return x.zfill(7)\n",
        "    elif x is not None and len(x) > 7:\n",
        "      return x[-7:]\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "  df['voter_id_no_part'] = df['voter_id_no_part'].apply(add_zeros)\n",
        "\n",
        "  def new_voter_id_col(num_part, str_part):\n",
        "    #global list_str_n\n",
        "    for i in list_str_n:\n",
        "      if str_part is not None and str_part != '' and (i in str_part or i[:2] in str_part or i[::2] in str_part or i[1:] in str_part):\n",
        "          return i + str(num_part)\n",
        "      if str_part == '' or str_part is None:\n",
        "        return None\n",
        "\n",
        "\n",
        "  df['voter_id_new'] = df.apply(lambda x: new_voter_id_col(x['voter_id_no_part'], x['voter_id_str_part']), axis = 1)\n",
        "  df['voter_id_new'] = df.voter_id_new.str.strip()\n",
        "\n",
        "\n",
        "  df.drop(['voter_id_no_part', 'voter_id_str_part', 'voter_id'], axis = 1, inplace = True)\n",
        "\n",
        "  return df\n",
        "\n",
        "#  def voter_id_str_slice(x):\n",
        "#    if x != '' and len(str(x)) > 3:\n",
        "#      return x[:3]\n",
        "#    else:\n",
        "#      return x\n",
        "#\n",
        "#  df['voter_id_str_part'] = df['voter_id_str_part'].apply(voter_id_str_slice)"
      ],
      "metadata": {
        "id": "4cf7YfnLAS4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Header Section"
      ],
      "metadata": {
        "id": "07YvJdz0C3j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def process_header_col(df):\n",
        "\n",
        "  df['header_section'] = df['header_section'].str.replace('/n', ' ')\n",
        "\n",
        "  df['Assembly_Constituency_No_and_Name'] = df['header_section'].str.extract(r'((?<=Assembly Constituency No and Name).*(?=Part))')\n",
        "  df['Assembly_Constituency_No_and_Name'] = df['Assembly_Constituency_No_and_Name'].str.replace(':', '', regex = True)\n",
        "  df['Assembly_Constituency_No_and_Name'] = df['Assembly_Constituency_No_and_Name'].str.strip()\n",
        "\n",
        "  df['Section_No_and_Name'] = df['header_section'].str.extract(r'((?<=Section No and Name).*(?=))')\n",
        "  df['Section_No_and_Name'] = df['Section_No_and_Name'].str.replace(': ', '')\n",
        "  df['Section_No_and_Name'] = df['Section_No_and_Name'].str.strip()\n",
        "\n",
        "  df['header_section'] = df['header_section'].str.replace('\\n', ' ')\n",
        "\n",
        "  df['Part_Number'] = df['header_section'].str.extract(r'((?<=Part number).*(?=Section))')\n",
        "\n",
        "  df['Part_Number'] = df['Part_Number'].str.replace(': ', '').str.strip()\n",
        "\n",
        "  df['Key'] = df['Assembly_Constituency_No_and_Name']\n",
        "  df['Key'] = df['Key'].str.replace('\\d', '', regex = True)\n",
        "  df['Key'] = df['Key'].str.replace('\\W', '', regex = True)\n",
        "\n",
        "  df['Constituency'] = df['Assembly_Constituency_No_and_Name']\n",
        "  df['Constituency'] = df['Constituency'].str.replace('\\d', '', regex = True)\n",
        "  df['Constituency'] = df['Constituency'].str.replace('\\W', '', regex = True)\n",
        "\n",
        "  def add_const_and_part(constituency_name, part_no):\n",
        "    return str(constituency_name) + '-' + str(part_no)\n",
        "\n",
        "  df['Key'] = df.apply(lambda x: add_const_and_part(x['Key'], x['Part_Number']), axis = 1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "KNeiZCsGBcyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataframe Editing"
      ],
      "metadata": {
        "id": "YoB_zqs9a2hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "def edit_df(df):\n",
        "\n",
        "  df = df.drop(['header_section'], axis = 1)\n",
        "  df = df.rename(columns = {'voter_id_new': 'Voter_id', 'voter_no': 'Voter_no'})\n",
        "\n",
        "  cols =  ['Voter_no', 'Voter_id', 'Name', 'Relation_Name', 'Relation_type', 'Age',\n",
        "         'Gender', 'House_Number', 'Assembly_Constituency_No_and_Name',\n",
        "          'Section_No_and_Name', 'Part_Number', 'Constituency', 'Key']\n",
        "\n",
        "  df = df[cols]\n",
        "\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "#  def fill_null_voter_ids(x):\n",
        "#    if x is None:\n",
        "#      x = str(uuid.uuid4())[:9]\n",
        "#      return '-' + x\n",
        "#    else:\n",
        "#      return x\n",
        "\n",
        "#  df['Voter_id'] = df['Voter_id'].apply(fill_null_voter_ids)\n",
        "\n",
        "#  df = df[df['Voter_id'].isnull() | ~ df[df['Voter_id'].notnull()].duplicated(subset = 'Voter_id', keep = 'first')]\n",
        "\n",
        "#  df.drop_duplicates(keep = 'first', inplace = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "7t4rlczmCKPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main Function"
      ],
      "metadata": {
        "id": "8yG_Bs1bCXXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "csv_files = Path(\"/content/drive/MyDrive/Raw_CSV_Files_all/Kanigiri_Raw_CSV_Files\").glob(\"*.csv\")\n",
        "\n",
        "for csv in csv_files:\n",
        "\n",
        "  filename = csv.stem\n",
        "\n",
        "  csv_path = '/content/drive/MyDrive/Raw_CSV_Files_all/Kanigiri_Raw_CSV_Files/' + filename + '.csv'\n",
        "\n",
        "  df = pd.read_csv(csv_path)\n",
        "  df = process_text_col(df)\n",
        "  df = process_voter_id_col(df)\n",
        "  df = process_header_col(df)\n",
        "  df = edit_df(df)\n",
        "\n",
        "  csv_path = '/content/drive/MyDrive/Raw_CSV_Files_all/Kanigiri_Clean_CSV_files/' + filename + '.csv'\n",
        "  df.to_csv(csv_path)\n"
      ],
      "metadata": {
        "id": "i1xZ7PKOC41S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merging the Files and removing dups"
      ],
      "metadata": {
        "id": "gCHSBrSLrsvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "csv_files = Path(\"/content/drive/MyDrive/Raw_CSV_Files_all/Kanigiri_Clean_CSV_files\").glob(\"*.csv\")\n",
        "\n",
        "\n",
        "cols =  ['Voter_no', 'Voter_id', 'Name', 'Relation_Name', 'Relation_type', 'Age',\n",
        "        'Gender', 'House_Number', 'Assembly_Constituency_No_and_Name',\n",
        "        'Section_No_and_Name', 'Part_Number', 'Constituency', 'Key']\n",
        "\n",
        "df_merged = pd.DataFrame(columns = cols)\n",
        "\n",
        "for csv in csv_files:\n",
        "\n",
        "  filename = csv.stem\n",
        "  csv_path = '/content/drive/MyDrive/Raw_CSV_Files_all/Kanigiri_Clean_CSV_files/' + filename + '.csv'\n",
        "  df = pd.read_csv(csv_path)\n",
        "  df_merged = pd.concat([df_merged, df], ignore_index=True, sort=False)\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/Raw_CSV_Files_all/Kanigiri_Clean_CSV_files/Merged_Kanigiri_CSV_file.csv'\n",
        "\n",
        "df_merged.to_csv(csv_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RZXdoXX5C6SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.drop(['Unnamed: 0', 'Voter_no'], axis = 1, inplace =True)\n",
        "\n",
        "df1 = df_merged[df_merged['Voter_id'].isnull()].drop_duplicates(keep = 'first')\n",
        "df2 = df_merged[df_merged['Voter_id'].notnull()].drop_duplicates(subset = 'Voter_id', keep = 'first')\n",
        "\n",
        "df_merged = pd.concat([df1, df2], ignore_index=True, sort=False)\n",
        "\n",
        "df_merged['Relation_Name'] = np.where(df_merged['Relation_Name'].isnull() & (df_merged['Relation_type'] == 5), 'NA', df_merged['Relation_Name'])\n",
        "\n",
        "\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/Raw_CSV_Files_all/Kanigiri_Clean_CSV_files/Merged_Kanigiri_CSV_file_noDups.csv'\n",
        "\n",
        "df_merged.to_csv(csv_path)"
      ],
      "metadata": {
        "id": "H0JMayvrGzii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
